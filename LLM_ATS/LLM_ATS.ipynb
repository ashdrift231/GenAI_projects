{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries from requirements.txt\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install localtunnel for exposing the Streamlit app\n",
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "qhYBe-wasS7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the Streamlit application code to a file named app.py\n",
        "%%writefile app.py\n",
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "import PyPDF2 as pdf\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "\n",
        "# NVIDIA API key (consider using environment variables for security)\n",
        "key = \"your_nvidia_api_key\"\n",
        "os.environ[\"NVIDIA_API_TOKEN\"] = key\n",
        "\n",
        "# Function to get response from the NVIDIA API\n",
        "def get_response(input):\n",
        "    client = ChatNVIDIA(\n",
        "        model=\"meta/llama3-70b-instruct\",\n",
        "        api_key=key,\n",
        "        temperature=0.5,\n",
        "        top_p=1,\n",
        "        max_tokens=1024,\n",
        "        )\n",
        "    response = client.invoke(input)\n",
        "    return response.content\n",
        "\n",
        "# Function to extract text from a PDF file\n",
        "def extract_pdf_text(uploaded_file):\n",
        "    reader=pdf.PdfReader(uploaded_file)\n",
        "    text=\"\"\n",
        "    for page in range(len(reader.pages)):\n",
        "        page=reader.pages[page]\n",
        "        text+=str(page.extract_text())\n",
        "    return text\n",
        "\n",
        "# Prompt Template for the AI model\n",
        "input_prompt=\"\"\"\n",
        "Hey Act Like a skilled or very experience ATS(Application Tracking System)\n",
        "with a deep understanding of tech field,software engineering,data science ,data analyst\n",
        "and big data engineer. Your task is to evaluate the resume based on the given job description.\n",
        "You must consider the job market is very competitive and you should provide\n",
        "best assistance for improving thr resumes. Assign the percentage Matching based\n",
        "on Jd and\n",
        "the missing keywords with high accuracy\n",
        "resume:{text}\n",
        "description:{jd}\n",
        "\n",
        "I want the response in one single string having the structure\n",
        "{{\"JD Match\":\"%\",\"MissingKeywords:[]\",\"Profile Summary\":\"\"}}\n",
        "\"\"\"\n",
        "\n",
        "## streamlit app\n",
        "st.title(\"Smart ATS\") # Set the title of the Streamlit app\n",
        "st.text(\"Improve Your Resume ATS\") # Add a text message to the app\n",
        "jd=st.text_area(\"Paste the Job Description\") # Create a text area for the user to paste the job description\n",
        "uploaded_file=st.file_uploader(\"Upload Your Resume\",type=\"pdf\",help=\"Please uplaod the pdf\")\n",
        "\n",
        "submit = st.button(\"Submit\")\n",
        "\n",
        "# Process the input when the submit button is clicked\n",
        "if submit:\n",
        "    if uploaded_file is not None:\n",
        "        text=extract_pdf_text(uploaded_file) # Extract text from the uploaded PDF\n",
        "        response=get_response(input_prompt+jd+text) # Get the response from the AI model\n",
        "        st.subheader(response) # Display the response as a subheader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZmpPlp8sAm9",
        "outputId": "d0501241-c2e6-488b-f343-9460856ca6b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Streamlit app and expose it using localtunnel\n",
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBuR8aXMso1W",
        "outputId": "10073134-474b-4d7a-b121-fcbc7754de32"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.218.109\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0Kyour url is: https://shaggy-steaks-walk.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5exfUDdUzIBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}